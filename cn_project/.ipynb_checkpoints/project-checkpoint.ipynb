{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying with pandas.read_html but it only works on certain type of tables\n",
    "#tables = pd.read_html(\"https://www.theweathernetwork.com/ca/hourly-weather-forecast/ontario/windsor\")\n",
    "#print (tables[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"https://www.theweathernetwork.com/ca/hourly-weather-forecast/ontario/windsor\"\n",
    "\n",
    "f = urllib.request.urlopen(link)\n",
    "myfile = f.read()\n",
    "print(myfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "link = \"https://www.architecture.com/FindAnArchitect/FAAPractices.aspx?display=50\"\n",
    "\n",
    "html = requests.get(link).text\n",
    "\n",
    "\"\"\"If you do not want to use requests then you can use the following code below \n",
    "   with urllib (the snippet above). It should not cause any issue.\"\"\"\n",
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "res = soup.findAll(\"article\", {\"class\": \"listingItem\"})\n",
    "for r in res:\n",
    "    print(\"Company Name: \" + r.find('a').text)\n",
    "    print(\"Address: \" + r.find(\"div\", {'class': 'address'}).text)\n",
    "    print(\"Website: \" + r.find_all(\"div\", {'class': 'pageMeta-item'})[3].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from dateutil import parser, rrule\n",
    "from datetime import datetime, time, date\n",
    "import time\n",
    "\n",
    "def getRainfallData(station, day, month, year):\n",
    "    \"\"\"\n",
    "    Function to return a data frame of minute-level weather data for a single Wunderground PWS station.\n",
    "    \n",
    "    Args:\n",
    "        station (string): Station code from the Wunderground website\n",
    "        day (int): Day of month for which data is requested\n",
    "        month (int): Month for which data is requested\n",
    "        year (int): Year for which data is requested\n",
    "    \n",
    "    Returns:\n",
    "        Pandas Dataframe with weather data for specified station and date.\n",
    "    \"\"\"\n",
    "    url = \"http://www.wunderground.com/weatherstation/WXDailyHistory.asp?ID={station}&day={day}&month={month}&year={year}&graphspan=day&format=1\"\n",
    "    full_url = url.format(station=station, day=day, month=month, year=year)\n",
    "    # Request data from wunderground data\n",
    "    response = requests.get(full_url, headers={'User-agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'})\n",
    "    data = response.text\n",
    "    # remove the excess <br> from the text data\n",
    "    data = data.replace('<br>', '')\n",
    "    # Convert to pandas dataframe (fails if issues with weather station)\n",
    "    try:\n",
    "        dataframe = pd.read_csv(io.StringIO(data), index_col=False)\n",
    "        dataframe['station'] = station\n",
    "    except Exception as e:\n",
    "        print(\"Issue with date: {}-{}-{} for station {}\".format(day,month,year, station))\n",
    "        return None\n",
    "    return dataframe\n",
    "    \n",
    "# Generate a list of all of the dates we want data for\n",
    "start_date = \"2015-01-01\"\n",
    "end_date = \"2015-12-31\"\n",
    "start = parser.parse(start_date)\n",
    "end = parser.parse(end_date)\n",
    "dates = list(rrule.rrule(rrule.DAILY, dtstart=start, until=end))\n",
    "\n",
    "# Create a list of stations here to download data for\n",
    "stations = [\"IDUBLINF3\", \"IDUBLINF2\", \"ICARRAIG2\", \"IGALWAYR2\", \"IBELFAST4\", \"ILONDON59\", \"IILEDEFR28\"]\n",
    "# Set a backoff time in seconds if a request fails\n",
    "backoff_time = 10\n",
    "data = {}\n",
    "\n",
    "# Gather data for each station in turn and save to CSV.\n",
    "for station in stations:\n",
    "    print(\"Working on {}\".format(station))\n",
    "    data[station] = []\n",
    "    for date in dates:\n",
    "        # Print period status update messages\n",
    "        if date.day % 10 == 0:\n",
    "            print(\"Working on date: {} for station {}\".format(date, station))\n",
    "        done = False\n",
    "        while done == False:\n",
    "            try:\n",
    "                weather_data = getRainfallData(station, date.day, date.month, date.year)\n",
    "                done = True\n",
    "            except ConnectionError as e:\n",
    "                # May get rate limited by Wunderground.com, backoff if so.\n",
    "                print(\"Got connection error on {}\".format(date))\n",
    "                print(\"Will retry in {} seconds\".format(backoff_time))\n",
    "                time.sleep(10)\n",
    "        # Add each processed date to the overall data\n",
    "        data[station].append(weather_data)\n",
    "    # Finally combine all of the individual days and output to CSV for analysis.\n",
    "    pd.concat(data[station]).to_csv(\"data/{}_weather.csv\".format(station))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import os\n",
    "import urllib.request "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(os.path.expanduser(r\"/Weather Data.csv\"), \"wb\")\n",
    "file.write(\n",
    "        b\"Date,Mean Temperature,Max Temperature,Min Temperature,Heating Degree Days, Dew Point, Average Humidity, Max Humidity, Minimum Humidity, Precipitation, Sea Level Pressure, Average Wind Speed, Maximum Wind Speed, Visibility, Events\" + b\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary modules\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib, os, urllib.request\n",
    "\n",
    "# creating CSV file to be used - each title is separated by a comma\n",
    "file = open(os.path.expanduser(r\"~/Desktop/Weather Data.csv\"), \"wb\")\n",
    "file.write(\n",
    "        b\"Date,Mean Temperature,Max Temperature,Min Temperature,Heating Degree Days, Dew Point, Average Humidity, Max Humidity, Minimum Humidity, Precipitation, Sea Level Pressure, Average Wind Speed, Maximum Wind Speed, Visibility, Events\" + b\"\\n\")\n",
    "\n",
    "# Looping based on year (vYear), month (vMonth) and date vDate)\n",
    "# - if you want 2014 to 2015, your year range should be range(2014,2016)\n",
    "# - if you want January to March, your month range should be range(1,4) - if you want everything than do range(1,13)\n",
    "# - if you want 1 to 12, your day range shoudl be range(1,13) - if you want everything than do range (1,32)\n",
    "\n",
    "for vYear in range(2000, 2016):\n",
    "    for vMonth in range(1, 13):\n",
    "        for vDay in range(1, 32):\n",
    "            # go to the next month, if it is a leap year and greater than the 29th or if it is not a leap year\n",
    "            # and greater than the 28th\n",
    "            if vYear % 4 == 0:\n",
    "                if vMonth == 2 and vDay > 29:\n",
    "                    break\n",
    "            else:\n",
    "                if vMonth == 2 and vDay > 28:\n",
    "                    break\n",
    "            # go to the next month, if it is april, june, september or november and greater than the 30th\n",
    "            if vMonth in [4, 6, 9, 11] and vDay > 30:\n",
    "                break\n",
    "\n",
    "            # defining the date string to export and go to the next day using the url\n",
    "            theDate = str(vYear) + \"/\" + str(vMonth) + \"/\" + str(vDay)\n",
    "\n",
    "            # the new url created after each day\n",
    "            theurl = \"http://www.wunderground.com/history/airport/CYTZ/\" + theDate + \"/DailyHistory.html\"\n",
    "            # extract the source data for analysis\n",
    "            thepage = urllib.request.urlopen(theurl)\n",
    "            soup = BeautifulSoup(thepage, \"html.parser\")\n",
    "            MaxWindSpeed = Visibility = Events = AvgWindSpeed = SeaLevelPressure = Precipitation = MinHumidity = MaxHumidity = AvgHumidity = DewPoint = HeatingDegreeDays = Min = Max = Mean = \"N/A\"\n",
    "            for temp in soup.find_all('tr'):\n",
    "                if temp.text.strip().replace('\\n', '')[:6] == 'Actual' or temp.text.strip().replace('\\n', '')[-6:] == \"Record\":\n",
    "                    pass\n",
    "                elif temp.text.replace('\\n', '')[-7:] == \"RiseSet\":\n",
    "                    break\n",
    "                elif temp.find_all('td')[0].text == \"Mean Temperature\":\n",
    "                    if temp.find_all('td')[1].text.strip() == \"-\":\n",
    "                        Mean = \"N/A\"\n",
    "                    else:\n",
    "                        Mean = temp.find_all('td')[1].find(attrs={\"class\": \"wx-value\"}).text\n",
    "                elif temp.find_all('td')[0].text == \"Max Temperature\":\n",
    "                    if temp.find_all('td')[1].text.strip() == \"-\":\n",
    "                        Max = \"N/A\"\n",
    "                    else:\n",
    "                        Max = temp.find_all('td')[1].find(attrs={\"class\": \"wx-value\"}).text\n",
    "                elif temp.find_all('td')[0].text == \"Min Temperature\":\n",
    "                    if temp.find_all('td')[1].text.strip() == \"-\":\n",
    "                        Min = \"N/A\"\n",
    "                    else:\n",
    "                        Min = temp.find_all('td')[1].find(attrs={\"class\": \"wx-value\"}).text\n",
    "                elif temp.find_all('td')[0].text == \"Growing Degree Days\":\n",
    "                    if temp.find_all('td')[1].text.strip() == \"-\":\n",
    "                        GrowingDegreeDays = \"N/A\"\n",
    "                    else:\n",
    "                        GrowingDegreeDays = temp.find_all('td')[1].text\n",
    "                elif temp.find_all('td')[0].text == \"Heating Degree Days\":\n",
    "                    if temp.find_all('td')[1].text.strip() == \"-\":\n",
    "                        HeatingDegreeDays = \"N/A\"\n",
    "                    else:\n",
    "                        HeatingDegreeDays = temp.find_all('td')[1].text\n",
    "                elif temp.find_all('td')[0].text == \"Dew Point\":\n",
    "                    if temp.find_all('td')[1].text.strip() == \"-\" or temp.find_all('td')[1].text.strip() == \"\":\n",
    "                        DewPoint = \"N/A\"\n",
    "                    else:\n",
    "                        DewPoint = temp.find_all('td')[1].find(attrs={\"class\": \"wx-value\"}).text\n",
    "                elif temp.find_all('td')[0].text == \"Average Humidity\":\n",
    "                    if temp.find_all('td')[1].text.strip() == \"-\" or temp.find_all('td')[1].text.strip() == \"\":\n",
    "                        AvgHumidity = \"N/A\"\n",
    "                    else:\n",
    "                        AvgHumidity = temp.find_all('td')[1].text\n",
    "                elif temp.find_all('td')[0].text == \"Maximum Humidity\":\n",
    "                    if temp.find_all('td')[1].text.strip() == \"-\" or temp.find_all('td')[1].text.strip() == \"\":\n",
    "                        MaxHumidity = \"N/A\"\n",
    "                    else:\n",
    "                        MaxHumidity = temp.find_all('td')[1].text\n",
    "                elif temp.find_all('td')[0].text == \"Minimum Humidity\":\n",
    "                    if temp.find_all('td')[1].text.strip() == \"-\" or temp.find_all('td')[1].text.strip() == \"\":\n",
    "                        MinHumidity = \"N/A\"\n",
    "                    else:\n",
    "                        MinHumidity = temp.find_all('td')[1].text\n",
    "                elif temp.find_all('td')[0].text == \"Precipitation\" and temp.find_all('td')[1].text.strip() != \"\":\n",
    "                    if temp.find_all('td')[1].text.strip() == \"-\" or temp.find_all('td')[1].text.strip() == \"\":\n",
    "                        Precipitation = \"N/A\"\n",
    "                    else:\n",
    "                        Precipitation = temp.find_all('td')[1].find(attrs={\"class\": \"wx-value\"}).text\n",
    "                elif temp.find_all('td')[0].text == \"Sea Level Pressure\" and temp.find_all('td')[1].text.strip() != \"\":\n",
    "                    if temp.find_all('td')[1].text.strip() == \"-\":\n",
    "                        SeaLevelPressure = \"N/A\"\n",
    "                    else:\n",
    "                        SeaLevelPressure = temp.find_all('td')[1].find(attrs={\"class\": \"wx-value\"}).text\n",
    "                elif temp.find_all('td')[0].text == \"Wind Speed\":\n",
    "                    if temp.find_all('td')[1].text.strip() == \"-\" or temp.find_all('td')[1].text.strip().replace('\\n','') == \"- ()\" or temp.find_all('td')[1].text.strip() == \"\":\n",
    "                        AvgWindSpeed = \"N/A\"\n",
    "                    else:\n",
    "                        AvgWindSpeed = temp.find_all('td')[1].find(attrs={\"class\": \"wx-value\"}).text\n",
    "                elif temp.find_all('td')[0].text == \"Max Wind Speed\":\n",
    "                    if temp.find_all('td')[1].text.strip() == \"-\" or temp.find_all('td')[1].text.strip() == \"\":\n",
    "                        MaxWindSpeed = \"N/A\"\n",
    "                    else:\n",
    "                        MaxWindSpeed = temp.find_all('td')[1].find(attrs={\"class\": \"wx-value\"}).text\n",
    "                elif temp.find_all('td')[0].text == \"Visibility\":\n",
    "                    if temp.find_all('td')[1].text.strip() == \"-\":\n",
    "                        Visibility = \"N/A\"\n",
    "                    else:\n",
    "                        Visibility = temp.find_all('td')[1].find(attrs={\"class\": \"wx-value\"}).text\n",
    "                elif temp.find_all('td')[0].text == \"Events\":\n",
    "                    if temp.find_all('td')[1].text.strip() == \"-\":\n",
    "                        Events = \"N/A\"\n",
    "                    else:\n",
    "                        Events = temp.find_all('td')[1].text.strip().replace(\",\", \" \").replace('\\n', '').replace('\\t','')\n",
    "                        break\n",
    "\n",
    "            # combining the values to be written to the CSV file\n",
    "            CombinedString = theDate + \",\" + Mean + \",\" + Max + \",\" + Min + \",\" + HeatingDegreeDays + \",\" + DewPoint + \",\" + AvgHumidity + \",\" + MaxHumidity + \",\" + MinHumidity + \",\" + Precipitation + \",\" + SeaLevelPressure + \",\" + AvgWindSpeed + \",\" + MaxWindSpeed + \",\" + Visibility + \",\" + Events + \"\\n\"\n",
    "            file.write(bytes(CombinedString, encoding=\"ascii\", errors='ignore'))\n",
    "\n",
    "            # printing to help with any debugging and tracking progress\n",
    "            print(CombinedString)\n",
    "\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
